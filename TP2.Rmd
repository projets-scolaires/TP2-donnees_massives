---
title: "tp2"
author: "GroupeB"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r importation-librairies, include=FALSE}
#install.packages("glmnet")
#install.packages("xgboost")
#install.packages("fastDummies")
#install.packages("plotROC")
#install.packages("rpart.plot")
#install.packages("tree")
library(tidyverse)
library(skimr)
library(dplyr)
library(readr)
library(rsample)
library(knitr)
library(lubridate)
library(caret)
library(nnet)    # régression multinomiale
library(onehot)
library(pROC)
library(plotROC)
library(ISLR2)
library(MASS)
library(fastDummies)
library(tree)
library(rpart)
library(rpart.plot)

```

```{r importation-des-fonctions, include=FALSE, eval=FALSE, echo=FALSE}
source("plot_distribution.R")
file.exists("outliers.R")
file.exists("plot_distribution.R")
```


## Introduction : 

Dans un contexte où les menaces informatiques se multiplient et évoluent rapidement, les centres d’opérations de sécurité (SOC) doivent être en mesure de détecter, classifier et répondre efficacement aux incidents de cybersécurité. Pour améliorer ces processus, Microsoft a développé la base de données GUIDE, qui constitue la plus grande collection publique d'incidents réels de sécurité. Cette base de données a été mise en place dans le cadre du développement du Copilot for Security Guided Response (CGR) et a pour objectif principal d’améliorer l’enquête, le triage et l’assainissement des incidents de sécurité.

**Problème rencontré :** La base de donnée fournie a **4147992** observations et 46 variables, soit 45 potentielles variables explicatives. Ceci a soulevé deux problèmes majeurs dans le cadre de notre travail :

**Problème1** : Le fichier est trop lourd ; il pèse plus d'un GigaOctet, ce qui ralentit les algorithmes de Machine learning, puisque nous n'avons pas accès aux super-calculateurs. Pour contourner cet obstacle, nous avons selectionné un échantillon de 25 000 observations que nous avons renommé df. Tout notre travail est basé sur cette nouvelle database. Mais l'exécution final s'est faite sur la BD originale

**Problème2** : En présence d'autant de variables cibles et d'autant d'observations, il y a un risque de surapprentissage.
Donc nous allons préter une attention particulière à la colinéarité entre les différentes variables. Et via une analyse par composantes principales, on pourra selectionner les prédicteurs les plus pertinents.




```{r importation-du-dataset,include = FALSE}
data<- read.csv("../data/GUIDE.csv")
```



```{r ecriture-du-dataset-de-travail,include=FALSE,eval=FALSE,echo=FALSE}
set.seed(2025)  
df_subset <- Database %>%
sample_n(25000)
write_csv(df_subset, "data_subset.csv")
```



```{r importation-du-sous-dataset, include=FALSE}
df<- read.csv("data_subset.csv")
df[df == ""] <- NA  
df[df == " "] <- NA 
df[df %in% c("NA", "N/A", "NULL", "#N/A")] <- NA 
head(df)
#View(df)
```


### 0. Méthodologie : 

1. A propos des donnees :

    1.1 importation et source des données (À propos de l'auteur) ;
    
    1.2 Description des variables ;
    
      * Variable cible,
      
      * Variables explicatives
      
    1.3 Gestion des valeurs manquantes ;
    
    1.4 gestion des valeurs manquantes ;
    
2. Visualisations sur un sous ensemble échantillonné de manière alléatoire :

    2.1 Les diagramme en barres ;
    
    2.2 Histogrammes ;
    
    2.3 Séries temporelles.
    
    
3. Apprentisssage non supervisé.

   3.1 Analyse par composantes principales
   
   3.2. Clustering : Méthode des k-means


4. Apprentissage supervisé.

     4.1 Régression logistique :
     
       * Creation des modèles Backward, Forward, both
       
       * Choix du meilleur modèle par validation croisée
     
     4.2 Arbres de décision
     
       * Construction d'un arbre de décision
       
       * Élagage de l'arbre et choix des paramètre par validation croisée
       
5. Déploiement du meilleur modèle parmi les précédants sur la vrai BD

     5.1 Pré-traitement de la BD
     
     5.2 Mise en production
     
6. Conclusion :

  6.1 Quelques recommandations 
  
  6.2 Pour aller plus loin 

     

    
### 1. A propos des donnees

####  1.1 À propos de l'auteur ;

Cette base de données est accessible en libre téléchargement via kagle(https://www.kaggle.com/datasets/Microsoft/microsoft-security-incident-prediction?select=GUIDE_Train.csv).

Les auteurs sont : 

Microsoft (Propriétaire)

Scott Freitas (Administrateur)

amirh gharib (Editeur)

Rob McCann (Editeur)

Jovan Kalajdjieski (Editeur).

cette base englobe plus de 13 millions d'éléments de preuve sur 33 types d'entités, dont 1,6 million d'alertes et 1 million d'incidents annotés avec des étiquettes de triage provenant de clients sur une période de deux semaines. Cette télémétrie a été collectée auprès des clients Microsoft Defender XDR, englobant divers produits tels que des terminaux, des périphériques réseau, des environnements cloud, des systèmes de messagerie, etc.
(pris dans le site de l'auteur)
  
####  1.2 Description des variables :


##### **La Variable cible** : IncidentGrade : (La gravité de l'incident).

  Cette variables va nous aider à identifier la gravité des différents incidents.
  
##### **Variables explicatives potentielles** :

**Id** : Identifiant unique pour chaque paire OrgId-IncidentId.

**OrgId** : Identifiant de l'organisation.

**IncidentId** : Identifiant unique de l'incident au sein de l'organisation.

**AlertId** : Identifiant unique pour une alerte.

**Timestamp** : Date et heure de création de l’alerte.

**DetectorId** : Identifiant unique du détecteur ayant généré l’alerte.

**AlertTitle** : Titre de l’alerte.

**Category** : Catégorie de l’alerte.

**MitreTechniques** : techniques d'attaque qui ont été identifiées dans une alerte de sécurité, basées sur le framework MITRE ATT&CK.

**IncidentGrade** : Niveau de gravité attribué à l’incident par le SOC.

**ActionGrouped** : Action de remédiation de l’alerte par le SOC (niveau général).

**ActionGranular** : Action de remédiation de l’alerte par le SOC (niveau détaillé).

**EntityType** : Type d’entité impliquée dans l’alerte.

**EvidenceRole** : Rôle de la preuve dans l’enquête.

**DeviceId** : Identifiant unique du dispositif.

**Sha256** : Empreinte SHA-256 du fichier.

**IpAddress** : Adresse IP impliquée.

**Url** : URL impliquée.

**AccountSid** : Identifiant du compte on-premises.

**AccountUpn** : Identifiant du compte email.

**AccountObjectId** : Identifiant du compte Entra ID.

**AccountName** : Nom du compte on-premises.

**DeviceName** : Nom du dispositif.

**NetworkMessageId** : Identifiant au niveau organisationnel pour le message email.

**EmailClusterId** : Identifiant unique du cluster d’emails.

**RegistryKey** : Clé de registre impliquée.

**RegistryValueName** : Nom de la valeur du registre.

**RegistryValueData** : Données de la valeur du registre.

**ApplicationId** : Identifiant unique de l’application.

**ApplicationName** : Nom de l’application.

**OAuthApplicationId** : Identifiant de l’application OAuth.

**ThreatFamily** : Famille de logiciels malveillants associée à un fichier.

**FileName** : Nom du fichier.

**FolderPath** : Chemin du dossier contenant le fichier.

**ResourceIdName** : Nom de la ressource Azure.

**ResourceType** : Type de ressource Azure.

**Roles** : Métadonnées supplémentaires sur le rôle de la preuve dans l’alerte.

**OSFamily** : Famille du système d’exploitation.

**OSVersion** : Version du système d’exploitation.

**AntispamDirection** : Direction du filtre antispam.

**SuspicionLevel** : Niveau de suspicion.

**LastVerdict** : Verdict final de l’analyse de la menace.

**CountryCode** : Code du pays où la preuve a été trouvée.

**State** : État où la preuve a été trouvée.

**City** : Ville où la preuve a été trouvée.

Les variables sont réparties en 31 numériques et 15 catégorielles.

En réalité,les variables numérique sont en fait des id et des codes . ==> ce sont des variables catégorique à 
proprement parler. On devra modifier le type dans les traitements.




Nous constatons qu'il ya beaucoup de colonnes qui doivent être supprimées par ce que
Ce sont des Id --> Elles sont facilement identifiablesde façon unique et donc,
non performants pour les algorithmes d'apprentissage machine ;


#####  **Supression des colonnes non pertinentes pour l'étude** 

```{r suppression-colonnes-id}
col_a_supprimer = c("Id", "OrgId" ,"IncidentId","AlertId","DetectorId" ,
                    "DeviceId","AccountSid","AccountObjectId",
                    "NetworkMessageId","EmailClusterId","ApplicationId",
                    "OAuthApplicationId","ResourceIdName")
for (colonne in col_a_supprimer){
  df[[colonne]] <- NULL
}
```
Bien qu'elles sont des  identifiant des données,

* Les variables "AccountUpn" et "AccountName" sont conservées par ce que, bien qu'étant des failles 
d'identification, elles rapportent des analyses sur les comptes utilisateurs,ce qui pourrait permettre de comprendre
la fraude.

* "DeviceName" a été conservé pour effectuer une analyse sur les attaques récurrentes sur certains appareils.

* On conserve "FileName" et "Sha256" pour tenir compte des fichiers malveillants récurrents.

```{r valeurs-manquantes}
valeurs_manquantes <- colSums(is.na(df))
pourcentage_nan <- (valeurs_manquantes / nrow(df)) * 100
valeurs_manquantes <- data.frame(
  Column = names(valeurs_manquantes),
  Missing_Values = valeurs_manquantes,
  Pourcentage_NaN = pourcentage_nan
) %>%
  filter(Pourcentage_NaN != 0) %>%
  arrange(desc(Pourcentage_NaN))
print(valeurs_manquantes)
```
* On va supprimer les colonnes "ActionGrouped", "ActionGranular", "ResourceType",
"ThreatFamily","AntispamDirection", "Roles"

```{r suspicionLevel, include =FALSE}
df %>%
  count(SuspicionLevel, sort = TRUE)
```


Dans la  colonne *'SuspicionLevel'* , la valeur manquante  signifie que la transaction est non suspecte ou
non évaluée. 


```{r LastVerdict, include= FALSE}
df %>%
  count(LastVerdict, sort = TRUE)
```
La valeur manquante  dans la colone *'LastVerdict'* signifie qu'il n'y a pas encore de verdict, ou que le verdict est inconnu



```{r MitreTechniques, include=FALSE}
df %>%
  count(MitreTechniques, sort = TRUE)
```

Dans la colonne *'MitreTechniques'* On va remplacer les valeurs manquantes par "Unknown"



```{r gestion-des-nan, include=FALSE}
col_a_supprimer = c("ActionGrouped","ActionGranular","ResourceType","ThreatFamily",
             "AntispamDirection", "Roles")
for (col in  col_a_supprimer){
  df[[col]] <- NULL
}

df$SuspicionLevel[is.na(df$SuspicionLevel)] <- "Not Suspicious"
df$LastVerdict[is.na(df$LastVerdict)] <- "Pending Analysis"
df$MitreTechniques[is.na(df$MitreTechniques)] <- "Unknown"
```



```{r statistiques}
skim(df) %>%
  kable()
```

Plusieurs colonnes ne sont pas dans le bon type, on va les transformer.
Notons déjà que dans notre situation particulière, toutes les colonnes numériques devraient etre categorielles

```{r changement-type-colonnes, include= FALSE}
df$Timestamp <- as.Date(df$Timestamp, format = "%Y-%m-%d")


df <- df %>%
  mutate(across(where(is.numeric), as.factor),
    across(where(is.character), as.factor))
```

### 2. Visualisation

```{r visualisation-mitre-technique}

technique_counts <- df %>%
  group_by(MitreTechniques) %>%
  summarise(Count = n())

techniques_ordone <- technique_counts %>%
  arrange(desc(Count))

ggplot(data = head(techniques_ordone, 10), 
       aes(y = fct_reorder(MitreTechniques, Count), x = Count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "MITRE Techniques Top10",
    x= " ",
    y  = " "
  ) +
  theme_minimal() 
```

**interprétation** : 

La majorité des alertes sont associées à «Unknown» , ce qui signifie qu'on n'est pas capable de répérer la source et les méthodes de plusiers attaques. On devrait renforcer davantage la cibersécurité et former les employés, ou recruter des spécialistes.

Les techniques T1078, T1566, et T1133 sont les plus courantes après "Unknown", ce qui suggère que ces méthodes sont des vecteurs d'attaque privilégiés.

Certaines attaques combinent plusieurs techniques , ce qui signifie qu'un modèle de détection efficace doit prendre en compte les relations entre ces différentes méthodes .

```{r incident-Grade-visualisation}
IncidentGrade_count <- df %>%
  group_by(IncidentGrade) %>%
  summarise(Count = n()) 

ggplot(data = IncidentGrade_count, 
       aes(x = fct_reorder(IncidentGrade, Count), y = Count)) +  
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "Distribution des Incident Grades",
    x = "Incident",
    y = " "
  ) +
  theme_minimal()

```

**Interpretation** :  Le nombre élevé de BenignPositive et FalsePositive indique que le système génère beaucoup d'alertes inutiles (bruit).Ce qui est contre productif.
Une première recommandation est déjà de  rafinner et  d'améliorer le système d'alerte pour qu'il capte moin de bruit.


```{r repartition-categories}
category_counts <- df %>%
  count(Category, name = "Count") %>%  
  arrange(desc(Count))  

top_4_categories <- category_counts %>%
  head(4) 


autres_count <- sum(category_counts$Count) - sum(top_4_categories$Count)

top_5_categories <- top_4_categories %>%
  add_row(Category = "Autres", Count = autres_count)


ggplot(top_5_categories, aes(x = fct_reorder(Category, Count), y = Count, fill = Category)) +
  geom_bar(stat = "identity") +
  coord_flip() +  # Met les barres à l'horizontale
  labs(title = "Distribution des Catégories", x = "Catégorie", y = "Nombre") +
  theme_minimal() +
  scale_fill_viridis_d()


```


**interpretation** :

*Initial Access*est la catégorie la plus fréquente Cela signifie que la majorité des alertes concernent des tentatives d'accès initiales (ex. hameçonnage, exploitation de vulnérabilités).

*Exfiltration*arrive en deuxième position Cela correspond aux tentatives de vol de données en dehors du réseau cible ce qui indique aussi que des attaquants ont réussi à pénétrer les systèmes et tenter d'exfiltrer des informations sensibles.

*SuspiciousActivity* Comportements suspects qui ne sont pas nécessairement confirmés comme des attaques.
*CommandAndControl* Signale qu'un attaquant tente d'établir une communication avec un serveur distant.
*Impact* est la catégorie la moins fréquente cela signifie que les incidents ayant un effet direct et destructeur sont moins courants du à une bonne capacité de détection précoce.

*Autres* cette catégorie regroupe toutes les autres catégories moins fréquentes.

```{r IncidentGrade-fill-selon-IncidentGrade}
incident_counts <- df %>%
  count(IncidentGrade, name = "Count")

ggplot(incident_counts, aes(x = fct_reorder(IncidentGrade, Count), y = Count, fill = IncidentGrade)) +
  geom_bar(stat = "identity") +
  #coord_flip() +  # Met les barres à l'horizontale
  labs(title = "Distribution des Catégories", x = "Catégorie", y = "Nombre") +
  theme_minimal() +
  scale_fill_viridis_d()

```

**interpretation** 

*BenignPositive*(Majoritaire) représente une grande partie du graphique. Ce qui signifie que le système présent
capture énormément de fausses alertes. 

*TruePositive* (Proportion élevée) indique que le système de détection a bien identifié de véritables incidents qui sont des alertes valides et confirmées comme étant des menaces .
Une proportion élevée de TruePositiveest un bon signe car cela signifie que la détection est efficace.

*FalsePositive* (Moins fréquents) ce sont des alertes générées à tort. Une proportion trop élevée de FalsePositive peut poser problème , car cela signifie que l'algorithme génère trop d'alertes inutiles , ce qui peut surcharger les analystes et réduire la confiance dans le système.

**Puisque nous voulons faire une regression logistique pour prédire la variable 'IncidentGrade', nous allons
modifier cette dernière pour obtenir juste deux classes de la façon suivante :**

BenignPositive --> negatif

FalsePositive --> negatif

TruePositive --> positif

```{r modification-IncidentGrade, include=FALSE}

df <- df %>%
  mutate(
    IncidentGrade = case_when(
      IncidentGrade == "BenignPositive" ~ "negatif",
      IncidentGrade == "FalsePositive" ~ "negatif",
      IncidentGrade == "TruePositive" ~ "positif"
    )
  )

```


```{r IncidentGrade-fill-selon-EntityType}
ggplot(df, aes(x = EntityType, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = "Nombre d'incidents par type d'entité selon  IncidentGrade",
    x = " ",
    y = " "
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred" ))  + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

```

**interpretation**

Les entités les plus affectées sont Ip, Machine, User, etMailMessage,ces entités sont les plus exposées aux incidents de sécurité et nécessairement une surveillance renforcée.

*IncidentGrade* est positif(rouge) ce qui confirme Incidents, User, Ip, et Machine présente un nombre élevé d'incidents positifs ce qui signifie que ces entités sont fréquemment compromises ou impliquées dans des attaques avérées.

*IncidentGrade* est négatif(bleu) certaines entités ont un grand nombre d'incidents classés comme négatifs ( negatif en bleu) comme Ip, MailMessage, et Machine ce qui peut indiquer quil ya trop de fausses alertes,des règles de détection trop sensibles oubien un filtrage inadéquat des menaces réelles .

Certaines entités ont beaucoup d'incidents négatifs mais peu de positifs ( OAuthApplication, Process, CloudApplication) ce qui indique que ces entités sont moins susceptibles d'être réellement compromises ou que les règles de détection sont mal calibrées pour elles.

Ont peut donc
prioriser la protection des entités User, Ip, etMachine car ce sont les cibles les plus fréquentes des attaques.
Réduire les faux positifs sur certaines entités ( MailMessage, Ip) afin dajuster les règles de détection pour éviter les alertes inutiles.
Analyser plus en détail les entités OAuthApplication, Process, et CloudApplication et vérifier si elles sont vraiment vulnérables ou si elles génèrent trop de fausses alertes.

```{r IncidentGrade-fill-selon-SuspicionLevel}

ggplot(df, aes(x = SuspicionLevel, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = " IncidentGrade par niveau de suspicion",
    x = "Niveau de suspicion",
    y = "Nombre d'incidents"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred"))  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation**

La catégorie *Not Suspicious* représente l'écrasante majorité des incidents cela signifie que la plupart des alertes générées ne sont pas considérées comme suspectes. En gros le système de détection identifie beaucoup d'incidents mais les juge non suspects .

La catégorie *"Incriminated"* n'a pas de données visibles dans le graphique, ce qui suggère soit une absence de cas, soit un nombre très faible.

*IncidentGrade* est positif(rouge) : On observe une proportion importante d'incidents positifs dans *Not Suspicious* ce qui signifie que les menaces réelles sont classées comme «non suspectes»

*Suspicious* contient relativement peu d'incidents la plupart des incidents dans cette catégorie sont des incidents négatifs ( negatif) , ce qui signifie que le modèle considère rarement des événements comme véritablement suspects. Cela peut indiquer que les seuils de suspicion sont trop stricts et n'identifient pas assez d'attaques.

Il faut donc analyser les vrais incidents ( positif) dans *Not Suspicious* pour voir s'il ya des modèles d'attaques cachées.
Comparer avec d'autres variables ( MitreTechniques, EntityType) pour identifier les entités les plus touchées dans chaque catégorie.



```{r IncidentGrade-fill-selon-Usage}

ggplot(df, aes(x = Usage, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = " IncidentGrade par Usage",
    x = "Usage",
    y = "Nombre d'incidents"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred" ))  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation**

Les entités *Public* génèrent un nombre d'incidents nettement plus élevé que les entités Private.
Cela signifie que les ressources publiques (ex. serveurs accessibles sur Internet, services cloud publics) sont beaucoup plus ciblées par des activités suspectes ou malveillantes.

*IncidentGrade* est positif(rouge):Le nombre d'incidents *positifs* est plus élevé dans *Public* que dans *Private*.Cela signifie que les attaques réussies sont plus fréquentes sur des ressources publiques car elle sont plus exposés et vulnérables.

*IncidentGrade* est négatif(bleu) :Les entités *Public* génèrent également un nombre élevé d'incidents négatifs, ce qui signifie que beaucoup d'alertes sont non confirmées. Dans *Private*, la proportion d'incidents positifs et négatifs semble plus équilibrée.

Il faut donc analyser les incidents positifs en Public pour identifier les vecteurs d'attaque principaux et evaluer les écarts entre Public et Private afin de voir pourquoi les ressources privées ont-elles moins d'incidents confirmés.

```{r IncidentGrade-evolution-dans-le-temps}

incident_grade_monthly <- df %>%
  mutate(Month = floor_date(Timestamp, "month")) %>%
  group_by(Month, IncidentGrade) %>%
  summarise(Count = n(), .groups = 'drop')

# Graphique de l'évolution des IncidentGrade dans le temps

ggplot(incident_grade_monthly, aes(x = Month, y = Count, color = IncidentGrade)) +
  geom_line(size = 1) +
  labs(
    title = "Évolution de IncidentGrade dans le Temps",
    x = "Mois",
    y = "Nombre d'Incidents",
    color = "IncidentGrade"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("negatif" = "skyblue", "positif" = "red")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation** : On remarque que les déclarations d'incidents sont stables durant l'hivers.
et le système ne capture que les transactions frauduleuse.

C'est en mai et Juin que se dégagent la majorité des signalements. Possible lien avec 
tous les mouvements qui se déroulent durant l'été ? c'est une question qu'il faudra explorer.

Faisons un zoom sur les fluxtuations pendant le mois de mai


```{r incidents-mai}
start_date <- as.Date("2024-05-01")
end_date <- as.Date("2024-08-30")

filtered_data <- df %>%
  filter(Timestamp >= start_date & Timestamp <= end_date)

daily_counts <- filtered_data %>%
  group_by(Date = Timestamp) %>%
  summarise(Count = n(), .groups = "drop")

ggplot(daily_counts, aes(x = Date, y = Count)) +
  geom_line(color = "skyblue", size = 1) +
  geom_point(color = "skyblue") +
  labs(
    title = paste("Incidents reportés de ", format(start_date, "%B %Y"), "à", format(end_date, "%B %Y")),
    x = "Date",
    y = "Numbre d'ncidents"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_date(date_breaks = "7 days", date_labels = "%d-%b") +
  geom_hline(yintercept = mean(daily_counts$Count), linetype = "dashed", color = "red")


```

**Interprétation** : 

On observe une augmentation brutale autour du 1er juin , où le nombre d'incidents passe de moins de 500 à plus de 1500 en quelques jours du a des activité malveillante.Après le pic début juin, le nombre d'incidents commence à redescendre , avec une apparition notable entre le 6 et le 13 juin.Une tendance clairement baissière après le 13 juin ce qui es du surement a une réponse efficace des équipes de cybersécurité ou une résolution des problèmes détectés début juin.
La ligne rouge indique la moyenne du nombre d'incidents sur la période .

Analysons les incidents entre le 1er et le 6 juin afin d'dentifier la cause du pic, vérifiions l'impact des contre-mesures après le 13 juin  Ont-elles été efficaces ?

**Un approche serait de limiter notre étude aux incidents se produisant entre le 16 mai et le 13 juin,
pour capter le flux de variation et optimiser le  modèle. Mais nous n'allons pas le faire dans le cadre de ce travail.**

### 3. Apprentissage non supervisé

#### Pré- traitement

Dans cette session, nous allons dans un premier temps préparer les colonnes da le base des données au complet,
par la suite nous batirons les différents modèles sur un échantillonage alléatoire de 25 000 observations pour 
accélérer les calculs.

Une fois le meilleur modèle trouvé, nous allons  revenir sur la base des données de 4 millions d'observations le deployer.

Il ne sera pas necessaire par la suite de retirer les 25000 observation déjà vues par le modèle, par ce qu'elles représentent  0.6% de l'ensemble des observation, ce qui est  négligeable.



Comptons le nombre de valeurs distinctes par colonnes pour déterminer le meilleur algorithme de conversion.



```{r valeurs-distinctes-par-colonne}
data$SuspicionLevel[is.na(data$SuspicionLevel)] <- "Not Suspicious"
data$LastVerdict[is.na(data$LastVerdict)] <- "Pending Analysis"
data$MitreTechniques[is.na(data$MitreTechniques)] <- "Unknown"

data <- data %>%
  mutate(
    IncidentGrade = case_when(
      IncidentGrade == "BenignPositive" ~ "negatif",
      IncidentGrade == "FalsePositive" ~ "negatif",
      IncidentGrade == "TruePositive" ~ "positif"
    )
  )

distinct_counts <- c()

for (col in colnames(df)) {
  distinct_counts[col] <- length(unique(data[[col]]))
}

df_resume <- data.frame(
  Colonne = names(distinct_counts),
  Nb_Valeurs_Distinctes = as.integer(distinct_counts)
)
df_resume



```

Il y a trop des colonnes ayant énormément de valeurs distinctes, ce problème rend impossible l'annalyse PCA, puisque nous n'avons pas assez de ressources pour le faire.

Pour contourner le problème, on va faire un oneHot Encoder uniquement sur les colonnes ayant 10 ou moins de 10 valeurs distinctes.

Quant aux autres colonnes, on va faire un encodage des fréquences. Nous sommes consciens que ca va un peu biaiser le résultat, mais c'est le seul moyen de se faire une idée sur les variables avec les ressources en notre disposition.

```{r compter-valeurs-distinctes-df}
df_10_et_moins <- df_resume[df_resume$Nb_Valeurs_Distinctes <= 10, ]
df_plus_10     <- df_resume[df_resume$Nb_Valeurs_Distinctes > 10, ]

df_10_et_moins <- data[, df_10_et_moins$Colonne]
df_plus_10 <- data[,df_plus_10$Colonne]

```


Le colonnes ont énnormément de valeurs distinctes, le meilleur algorithme ici sera **embeddings**, mais nous n'avons pas acces aux super calculateurs pour la mettre en oeuvre. 

Nous allons donc opter pour  **l'encodage à laide des proportions** sur les colonnes ayant plus de 10 valeurs distinctes, et l' Encodage One-Hot pour les autres colones.


```{r one-hot-encoder}
df_onehot <- dummy_cols(df_10_et_moins, remove_first_dummy = FALSE, remove_selected_columns = TRUE)

```
```{r encodage-frequences}
# Fonction pour encoder les fréquences
encode_frequencies <- function(df) {
  df_encoded <- df  # c'est pour eviter d'ecraser df
  
  for (col in colnames(df)) {
    if (is.factor(df[[col]]) | is.character(df[[col]])) {
      freq_table <- table(df[[col]])  # Créer la table des fréquences
      df_encoded[[col]] <- as.integer(factor(df[[col]], levels = names(freq_table)))  # Encoder les fréquences
    }
  }
  
  return(df_encoded)
}

# Appliquer la fonction à ton dataframe
df_encoded <- encode_frequencies(df_plus_10)

```


```{r reconstitue-data}

data_traite <- cbind(df_onehot, df_encoded)
data_traite <- data_traite[, sapply(data_traite, is.numeric)]

if ("IncidentGrade_negatif" %in% colnames(data_traite)) {
 data_traite <- subset(data_traite, select = -IncidentGrade_negatif)
 data_traite <- data_traite %>%
  rename(IncidentGrade = IncidentGrade_positif)
}


# Nettoyage des noms de colonnes pour enlever les espaces
names(data_traite) <- make.names(names(data_traite))
data_traite <- data_traite[sapply(data_traite, is.numeric)]
glimpse(data_traite) 

```


#### 3.1 Analyse par composantes principales.

Comme annoncé, On va maintenant copier 25000 observations de façon aléatoire sur data_traité 
pour batir notre modèle par la suite 

```{r extraction-sous-ensemble}
set.seed(2025)  
df_copie <- data_traite %>%
sample_n(25000)
```


```{r PCA}

pr.out <- prcomp(df_copie, scale = TRUE)
names(pr.out)
biplot(pr.out, scale = 0, 
       main = "Biplot des composantes principales",
       cex.main = 1.5, col.main = "navy")


plot(pr.out, main = "Variance expliquée par les composantes principales")

```

```{r visualisation PCA}
par(mfrow = c(1, 2))
pve <- summary(pr.out)$importance[2, ]

plot(pve, xlab = "Composante Principale",
     ylab = "Proportion de variance expliquée", 
     ylim = c(0, 1), type = "b",
     main = "Variance expliquée")

plot(cumsum(pve), xlab = "Composante Principale",
     ylab = "Variance expliquée cumulative", 
     ylim = c(0, 1), type = "b",
     main = "Variance expliquée cumulée")

```


Avec 20 composantes principales, on es capable d'expliquer environ 95% de la variabilité des observations.

#### 3.2 : Clustering --> Méthode des k-means

```{r diagramme-ebouli}
pr.out <- prcomp(df_copie, scale. = TRUE)

set.seed(2025)
wss=c()
for (k in 1:15) {
  km <- kmeans(df_copie, centers = k, nstart = 20)
  wss[k] <- km$tot.withinss
}


df_wss <- data.frame(
  k = 1:15,
  WSS = wss
)


ggplot(df_wss, aes(x = k, y = WSS)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:15) +
  labs(
    title = "Diagramme d’éboulis (k-means)",
    x = "Nombre de clusters",
    y = "Somme des carrés intra-cluster (WSS)"
  ) +
  theme_minimal()

```

On voit que le coude se trouveentre 2 et 4, donc il est égal à 3. Ainsi, il est judicieux de diviser le set en
3 clusters.

```{r regroupement-m-means}
km.out <- kmeans(df_copie, 3, nstart = 30)
km.out$size
```
On ne peut pas visualiser les cluster à cause de la dimensionnalité. Mais nous pouvons quand meme remarquer 
qu'il y a trois groupes différents ayant pour taimmes respectives `r km.out$size[1]` observations, `r km.out$size[2]` observations et `r km.out$size[3]` observations.

Il est possibles que ces groupes correspondent aux transaction frauduleuses, non frauduleuses et pas encore classifiées (on ne peut pas encore se prononcer sur la cardinalité de chaque ensemble)


### 4.  Apprentissage supervisé

#### 4.1 Regression logistique

Cette partie est inspirée de la page suivante : 

**https://stackoverflow.com/questions/53654193/how-to-generate-confusion-matrix-on-hold-out-sample-in-caret-xgbdart**

La variable cible étant incident grade, nous allons supprimer les colonnes 'IncidentGrade_negatif' pour éviter la 
colinéarité et prédire 'IncidentGrade_positif' .



```{r choix-meilleur-modele-logistique-cv, warning=FALSE,include=FALSE}
#df_copie <- df_copie[sapply(df_copie, is.numeric)]

if (!is.factor(data_traite$IncidentGrade)) {
  df_copie$IncidentGrade <- factor(df_copie$IncidentGrade, levels = c(0, 1), labels = c("negatif", "positif"))
}


modele_complet <- glm(IncidentGrade ~ ., data = df_copie, family = binomial)
modele_nul <- glm(IncidentGrade ~ 1, data = df_copie, family = binomial)

backward_ <- stepAIC(modele_complet, direction = "backward", trace = 0)
forward_ <- stepAIC(modele_nul, 
                         scope = list(lower = formula(modele_nul), upper = formula(modele_complet)),
                         direction = "forward", trace = 0)
both_ <- stepAIC(modele_complet, direction = "both", trace = 0)


entrainement <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 3,
  savePredictions = TRUE,
  classProbs = TRUE,
  summaryFunction = defaultSummary 
)



modeles <- list(
  backward = train(formula(backward_), 
                   data = df_copie,
                   method = "glm",
                   family = binomial,
                   trControl = entrainement),
  
  forward = train(formula(forward_), 
                  data = df_copie,
                  method = "glm",
                  family = binomial,
                  trControl = entrainement),
  
  both = train(formula(both_), 
               data = df_copie,
               method = "glm",
               family = binomial,
               trControl = entrainement)
  )


resultats <- resamples(modeles)
summary(resultats)
#bwplot(resultats)

 

performances <- sapply(modeles, function(x) mean(x$results$Accuracy))
meilleur_nom <- names(which.max(performances))
meilleur_modele_logistique <- modeles[[meilleur_nom]]

cat("\n MEILLEUR MODÈLE ")
cat("\n Méthode :", meilleur_nom)
cat("\nAccuracy moyen :", round(mean(meilleur_modele_logistique$results$Accuracy), 3))


pred <- meilleur_modele_logistique$pred
pred <- pred[pred$Resample == pred$Resample[1], ]

#cat("\n Statistiques de classification (confusion matrix) :\n")
#print(confusionMatrix(pred$pred, pred$obs))


```

```{r coefficient-meilleur-modele, include= FALSE}

#variables_selectionnees <- all.vars(formula(meilleur_modele_logistique)[-1])
#print(variables_selectionnees)

cat("log(odds) = ", 
    coef(meilleur_modele_logistique)[1], 
    paste0(sprintf(" + %.3f*%s", 
                  coef(meilleur_modele_logistique)[-1], 
                  names(coef(meilleur_modele_logistique)[-1])), 
          collapse = ""))


```


le code suivant a été inspiré de stack overflow. voici le lien vers la reférence :

**https://stackoverflow.com/questions/71516298/why-is-geom-roc-from-ggplot-vs-plot-roc-giving-such-drastic-difference-in-roc** 

```{r courbe-roc-logistique}

pred_prob <- predict(meilleur_modele_logistique,  df_copie, type = "prob")[, 2]

roc_obj <- roc(df_copie$IncidentGrade, pred_prob,
               levels = levels(df_copie$IncidentGrade), 
               direction = "<")              

ggplot() +
  geom_roc(aes(m = pred_prob, d = as.numeric(df_copie$IncidentGrade)-1), 
           labels = FALSE) +
  style_roc(theme = theme_minimal) +
  annotate("text", x = 0.75, y = 0.25, 
           label = paste("AUC =", round(auc(roc_obj), 3)))+
  style_roc()


```


**Interprétation** : La courbe est largement au dessus de la diagonale. Ce qui signifie que notre modèle est performent.


#### 4.2  Arbre de classification




```{r  arbre-de-classiffication}

arbre <- tree(IncidentGrade ~ ., data = df_copie)

set.seed(2025)
cv_resultats <- cv.tree(arbre, FUN = prune.misclass)

print(cv_resultats)
plot(cv_resultats$size, cv_resultats$dev, type = "b",
     xlab = "Taille de l’arbre", ylab = "Erreur de classification",
     main = "Validation croisée")

taille_opt <- cv_resultats$size[which.min(cv_resultats$dev)]

arbre_elague <- prune.misclass(arbre, best = taille_opt)


# Prédictions sur tout le jeu
pred <- predict(arbre_elague, newdata = df_copie, type = "class")

# Matrice de confusion et précision
confusion <- table(Prediction = pred, Réel = df_copie$IncidentGrade)
print(confusion)
accuracy <- mean(pred == df_copie$IncidentGrade)

summary(arbre_elague)


```


```{r construction-arbre}

plot(arbre_elague)
text(arbre_elague, pretty = 0)
```
```{r courbe-ROC-arbre}
#Aidé par ChatGPT
pred_prob <- predict(arbre_elague, newdata = df_copie, type = "vector")[, 2]

roc_curve <- roc(df_copie$IncidentGrade, pred_prob)

plot(roc_curve, legacy.axes = TRUE, main = "Courbe ROC", col = "blue", lwd = 2,
     xlab = "Taux de faux positifs (FPR)", ylab = "Taux de vrais positifs (TPR)")

auc_value <- auc(roc_curve)
text(0.6, 0.2, labels = paste("AUC = ", round(auc_value, 2)), col = "red", cex = 1.2)


```


### 5 Mise en production.

#### 5.1  Choix du modèle



En comparant les courbes ROC des modèles ci-dessus définis, il ressort que l'arbre de décision élagué est le meilleur, avec un AUC de **`r round(auc_value, 2)`**

C'est donc ce modèle que nous allons déployer sur la vrai base de données


De façon plus précise, le modèle qui sera deployé en production est le suivant : 


```{r modele-retenu}

plot(arbre_elague)
text(arbre_elague, pretty = 0)

```





  
```{r  mise-en-production, include =FALSE}
if (!is.factor(data_traite$IncidentGrade)) {
  data_traite$IncidentGrade <- factor(data_traite$IncidentGrade, levels = c(0, 1), labels = c("negatif", "positif"))
}
pred_vrai <- predict(arbre_elague, newdata = data_traite, type = "class")

# Matrice de confusion et précision
confusion <- table(Prediction = pred_vrai, Réel = data_traite$IncidentGrade)



accuracy <- mean(pred_vrai == data_traite$IncidentGrade)

```
```{r matrice-de-confusion}
confusion <- table(Prediction = pred_vrai, Réel = data_traite$IncidentGrade)

# En pourcentages globaux
confusion_pourcentage <- round(100 * confusion / sum(confusion), 2)
print(confusion_pourcentage)

```

**Interpretation : **


```{r Rappel}
TN <- confusion_pourcentage["negatif", "negatif"]  # Vrai négatif
FP <- confusion_pourcentage["positif", "negatif"]  # Faux positif
FN <- confusion_pourcentage["negatif", "positif"]  # Faux négatif
TP <- confusion_pourcentage["positif", "positif"]  # Vrai positif
rappel = TP/(TP+FN)*100
precision = TP/(TP + FP)*100
accuracy <- TP + TN

```
Ce modèle  détecte correctement `r round(TP,2)`% des fraudes (vrais positifs).

Il reconnaît bien les transactions normales ( `r round(TN,2)`% sont bien classées comme normales).

Le taux de faux positifs ( `r round(FP,2)`%) est faible . Donc il ne crie pas "fraude" trop souvent quand ce n’en est pas une.


**Ce qui est préoccupant**
 
Le modèle rate `r round(FN)` % des fraudes en les classant comme normales (faux négatifs). Ce sont les plus dangereuses, car des fraudes passent inaperçues dans ces cas.

Finalement, on peut conclure qu'on a obtenu un Modèle prudent, qui évite de faussement d'accuser une transaction honnête, Mais trop conservateur, car il laisse passer presque la moitié des fraudes.





### 6.   Conclusion

#### 6.1 Quelques recommandations  : 

1. Engager d'avantages des spécialistes en cibersécurité et former le personnel ;

2. Mettre sur pied des publicités de sensibilisation ; 

3. Mettre une surveillance accrue sur les ressources moins utilisées ;

4. Renforcer la surveillance et les mesures de sécurité en été ; 

5. Regarder particulièrement les opérations qui se sont effectuées avec les clés suivantes, dans l'ordre de priorité descandante.

```{r operations-suspectes,eval=FALSE, include=FALSE}
Registry_counts <- data %>%
  count(RegistryKey, name = "Count") %>%
  filter(Count <= 2) %>%
  arrange(Count)

transactions_suspectes <- data %>%
  filter(RegistryKey %in% Registry_counts$RegistryKey)

transactions_suspectes = transactions_suspectes[,c("RegistryKey", "AlertTitle", "Category", "LastVerdict", "Usage")]%>%
  head(25) %>%
  kable()


#La totalité sera fournies en fichier annexe nommé opérations suspectes
```

```{r courbe-roc-modele-deploye}
dep_pred_prob <- predict(arbre_elague, newdata = data_traite, type = "vector")[, 2]

roc_curve <- roc(data_traite$IncidentGrade, dep_pred_prob)

plot(roc_curve, legacy.axes = TRUE, main = "Courbe ROC", col = "blue", lwd = 2,
     xlab = "Taux de faux positifs (FPR)", ylab = "Taux de vrais positifs (TPR)")

auc_value <- auc(roc_curve)
text(0.6, 0.2, labels = paste("AUC = ", round(auc_value, 2)), col = "red", cex = 1.2)

```



#### 6.2 Aller plus loin

Pour améliorer la qualité de ce travail, il serait important de se doter d'un super calculateur
afin de pouvoir bénéficier des différentes ressources qui on conditionné certains de nos choix dans le cadre de ce travail.

On a aussi remarqué qu'il y a beaucoup de lignes de codes qui se repetaient et 
des opération qui étaient faites à la fois sur la base de données échantillonnée et sur la 
vrai base des données lors de la mise en production. Une bonne pratique sera aussi de créer les fonctions pour 
ces traitements et de les intégrer dans un pipeline afin d'automatiser les traitements dans le futur.

On devrait aussi raffiner d'avantage le modèle, car il laisse passer la moitié des fraudes, ce  qui est très dangeureux. Car  ne pas détecter une fraude est pire que faussement en suspecter une. 

