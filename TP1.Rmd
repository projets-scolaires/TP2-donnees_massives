---
title: "tp1"
author: "GroupeB"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r importation-librairies, include=FALSE}
#install.packages("glmnet")
#install.packages("xgboost")
#install.packages("fastDummies")
library(tidyverse)
library(skimr)
library(dplyr)
library(readr)
library(rsample)
library(knitr)
library(lubridate)
library(caret)   # machine learning
library(nnet)    # régression multinomiale
library(onehot)
library(xgboost) # regressiom multinomiale performante
library(ISLR2)
library(MASS)
library(fastDummies)

```

```{r importation-des-fonctions, include=FALSE, eval=FALSE, echo=FALSE}
source("plot_distribution.R")
file.exists("outliers.R")
file.exists("plot_distribution.R")
```


## Introduction : 

Dans un contexte où les menaces informatiques se multiplient et évoluent rapidement, les centres d’opérations de sécurité (SOC) doivent être en mesure de détecter, classifier et répondre efficacement aux incidents de cybersécurité. Pour améliorer ces processus, Microsoft a développé la base de données GUIDE, qui constitue la plus grande collection publique d'incidents réels de sécurité. Cette base de données a été mise en place dans le cadre du développement du Copilot for Security Guided Response (CGR) et a pour objectif principal d’améliorer l’enquête, le triage et l’assainissement des incidents de sécurité.

**Problème rencontré :** La base de donnée fournie a **4147992** observations et 46 variables, soit 45 potentielles variables explicatives. Ceci a soulevé deux problèmes majeurs dans le cadre de notre travail :

**Problème1** : Le fichier est trop lourd ; il pèse plus d'un GigaOctet, ce qui ralentit les algorithmes de Machine learning, puisque nous n'avons pas accès aux super-calculateurs. Pour contourner cet obstacle, nous avons selectionné un échantillon de 25 000 observations que nous avons renommé df. Tout notre travail est basé sur cette nouvelle database. Mais l'exécution final s'est faite sur la BD originale

**Problème2** : En présence d'autant de variables cibles et d'autant d'observations, il y a un risque de surapprentissage.
Donc nous allons préter une attention particulière à la colinéarité entre les différentes variables. Et via une analyse par composantes principales, on pourra selectionner les prédicteurs les plus pertinents.




```{r importation-du-dataset,include = FALSE}
#Database<- read.csv("../data/GUIDE_Train.csv")
```



```{r ecriture-du-dataset-de-travail,include=FALSE,eval=FALSE,echo=FALSE}
#set.seed(2025)  
#df_subset <- Database %>%
#sample_n(25000)
#write_csv(df_subset, "data_subset.csv")
```



```{r importation-du-sous-dataset, include=FALSE}
df<- read.csv("data_subset.csv")
df[df == ""] <- NA  
df[df == " "] <- NA 
df[df %in% c("NA", "N/A", "NULL", "#N/A")] <- NA 
head(df)
#View(df)
```


### 1. Méthodologie : 

1. A propos des donnees :

    1.1 importation et source des données (À propos de l'auteur) ;
    
    1.2 Description des variables ;
    
      * Variable cible,
      
      * Variables explicatives
      
    1.3 Gestion des valeurs manquantes ;
    
    1.4 gestion des valeurs manquantes ;
    
2. Visualisations sur l'ensemble de test :

    2.1 Les diagramme en barres ;
    
    2.2 
    
    
3. Regression logistique sur la BD échantillonnée alléatoirement.

   3.1 Separation de la BD en (80,20) = (entrainement,test)
   
   3.2. Construction du modèle : Approche **Backward**


4. Déploiement du modèle sur la BD originale.

     4.1 Préparation des données
     
     4.2 Regression
     
5. Quelques recommandations : 
     

    
### 1. A propos des donnees

####  1.1 À propos de l'auteur ;

Cette base de données est accessible en libre téléchargement via kagle(https://www.kaggle.com/datasets/Microsoft/microsoft-security-incident-prediction?select=GUIDE_Train.csv).

Les auteurs sont : 

Microsoft (Propriétaire)

Scott Freitas (Administrateur)

amirh gharib (Editeur)

Rob McCann (Editeur)

Jovan Kalajdjieski (Editeur).

cette base englobe plus de 13 millions d'éléments de preuve sur 33 types d'entités, dont 1,6 million d'alertes et 1 million d'incidents annotés avec des étiquettes de triage provenant de clients sur une période de deux semaines. Cette télémétrie a été collectée auprès des clients Microsoft Defender XDR, englobant divers produits tels que des terminaux, des périphériques réseau, des environnements cloud, des systèmes de messagerie, etc.
(pris dans le site de l'auteur)
  
####  1.2 Description des variables :


##### **La Variable cible** : IncidentGrade : (La gravité de l'incident).

  Cette variables va nous aider à identifier la gravité des différents incidents.
  
##### **Variables explicatives potentielles** :

**Id** : Identifiant unique pour chaque paire OrgId-IncidentId.

**OrgId** : Identifiant de l'organisation.

**IncidentId** : Identifiant unique de l'incident au sein de l'organisation.

**AlertId** : Identifiant unique pour une alerte.

**Timestamp** : Date et heure de création de l’alerte.

**DetectorId** : Identifiant unique du détecteur ayant généré l’alerte.

**AlertTitle** : Titre de l’alerte.

**Category** : Catégorie de l’alerte.

**MitreTechniques** : techniques d'attaque qui ont été identifiées dans une alerte de sécurité, basées sur le framework MITRE ATT&CK.

**IncidentGrade** : Niveau de gravité attribué à l’incident par le SOC.

**ActionGrouped** : Action de remédiation de l’alerte par le SOC (niveau général).

**ActionGranular** : Action de remédiation de l’alerte par le SOC (niveau détaillé).

**EntityType** : Type d’entité impliquée dans l’alerte.

**EvidenceRole** : Rôle de la preuve dans l’enquête.

**DeviceId** : Identifiant unique du dispositif.

**Sha256** : Empreinte SHA-256 du fichier.

**IpAddress** : Adresse IP impliquée.

**Url** : URL impliquée.

**AccountSid** : Identifiant du compte on-premises.

**AccountUpn** : Identifiant du compte email.

**AccountObjectId** : Identifiant du compte Entra ID.

**AccountName** : Nom du compte on-premises.

**DeviceName** : Nom du dispositif.

**NetworkMessageId** : Identifiant au niveau organisationnel pour le message email.

**EmailClusterId** : Identifiant unique du cluster d’emails.

**RegistryKey** : Clé de registre impliquée.

**RegistryValueName** : Nom de la valeur du registre.

**RegistryValueData** : Données de la valeur du registre.

**ApplicationId** : Identifiant unique de l’application.

**ApplicationName** : Nom de l’application.

**OAuthApplicationId** : Identifiant de l’application OAuth.

**ThreatFamily** : Famille de logiciels malveillants associée à un fichier.

**FileName** : Nom du fichier.

**FolderPath** : Chemin du dossier contenant le fichier.

**ResourceIdName** : Nom de la ressource Azure.

**ResourceType** : Type de ressource Azure.

**Roles** : Métadonnées supplémentaires sur le rôle de la preuve dans l’alerte.

**OSFamily** : Famille du système d’exploitation.

**OSVersion** : Version du système d’exploitation.

**AntispamDirection** : Direction du filtre antispam.

**SuspicionLevel** : Niveau de suspicion.

**LastVerdict** : Verdict final de l’analyse de la menace.

**CountryCode** : Code du pays où la preuve a été trouvée.

**State** : État où la preuve a été trouvée.

**City** : Ville où la preuve a été trouvée.

Les variables sont réparties en 31 numériques et 15 catégorielles.

En réalité,les variables numérique sont en fait des id et des codes . ==> ce sont des variables catégorique à 
proprement parler. On devra modifier le type dans les traitements.




Nous constatons qu'il ya beaucoup de colonnes qui doivent être supprimées par ce que
Ce sont des Id --> Elles sont facilement identifiablesde façon unique et donc,
non performants pour les algorithmes d'apprentissage machine ;


#####  **Supression des colonnes non pertinentes pour l'étude** 

```{r suppression-colonnes-id}
col_a_supprimer = c("Id", "OrgId" ,"IncidentId","AlertId","DetectorId" ,
                    "DeviceId","AccountSid","AccountObjectId",
                    "NetworkMessageId","EmailClusterId","ApplicationId",
                    "OAuthApplicationId","ResourceIdName")
for (colonne in col_a_supprimer){
  df[[colonne]] <- NULL
}
```
Bien qu'elles sont des  identifiant des données,

* Les variables "AccountUpn" et "AccountName" sont conservées par ce que, bien qu'étant des failles 
d'identification, elles rapportent des analyses sur les comptes utilisateurs,ce qui pourrait permettre de comprendre
la fraude.

* "DeviceName" a été conservé pour effectuer une analyse sur les attaques récurrentes sur certains appareils.

* On conserve "FileName" et "Sha256" pour tenir compte des fichiers malveillants récurrents.

```{r valeurs-manquantes}
valeurs_manquantes <- colSums(is.na(df))
pourcentage_nan <- (valeurs_manquantes / nrow(df)) * 100
valeurs_manquantes <- data.frame(
  Column = names(valeurs_manquantes),
  Missing_Values = valeurs_manquantes,
  Pourcentage_NaN = pourcentage_nan
) %>%
  filter(Pourcentage_NaN != 0) %>%
  arrange(desc(Pourcentage_NaN))
print(valeurs_manquantes)
```
* On va supprimer les colonnes "ActionGrouped", "ActionGranular", "ResourceType",
"ThreatFamily","AntispamDirection", "Roles"

```{r suspicionLevel, include =FALSE}
df %>%
  count(SuspicionLevel, sort = TRUE)
```


Dans la  colonne *'SuspicionLevel'* , la valeur manquante  signifie que la transaction est non suspecte ou
non évaluée. 


```{r LastVerdict, include= FALSE}
df %>%
  count(LastVerdict, sort = TRUE)
```
La valeur manquante  dans la colone *'LastVerdict'* signifie qu'il n'y a pas encore de verdict, ou que le verdict est inconnu



```{r MitreTechniques, include=FALSE}
df %>%
  count(MitreTechniques, sort = TRUE)
```

Dans la colonne *'MitreTechniques'* On va remplacer les valeurs manquantes par "Unknown"



```{r gestion-des-nan, include=FALSE}
col_a_supprimer = c("ActionGrouped","ActionGranular","ResourceType","ThreatFamily",
             "AntispamDirection", "Roles")
for (col in  col_a_supprimer){
  df[[col]] <- NULL
}

df$SuspicionLevel[is.na(df$SuspicionLevel)] <- "Not Suspicious"
df$LastVerdict[is.na(df$LastVerdict)] <- "Pending Analysis"
df$MitreTechniques[is.na(df$MitreTechniques)] <- "Unknown"
```



```{r statistiques}
skim(df) %>%
  kable()
```

Plusieurs colonnes ne sont pas dans le bon type, on va les transformer.
Notons déjà que dans notre situation particulière, toutes les colonnes numériques devraient etre categorielles

```{r changement-type-colonnes, include= FALSE}
df$Timestamp <- as.Date(df$Timestamp, format = "%Y-%m-%d")


df <- df %>%
  mutate(across(where(is.numeric), as.factor),
    across(where(is.character), as.factor))
```

### 2. Visualisation

```{r visualisation-mitre-technique}

technique_counts <- df %>%
  group_by(MitreTechniques) %>%
  summarise(Count = n())

techniques_ordone <- technique_counts %>%
  arrange(desc(Count))

ggplot(data = head(techniques_ordone, 10), 
       aes(y = fct_reorder(MitreTechniques, Count), x = Count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "MITRE Techniques Top10",
    x= " ",
    y  = " "
  ) +
  theme_minimal() 
```

**interprétation** : 

La majorité des alertes sont associées à «Unknown» , ce qui signifie qu'on n'est pas capable de répérer la source et les méthodes de plusiers attaques. On devrait renforcer davantage la cibersécurité et former les employés, ou recruter des spécialistes.

Les techniques T1078, T1566, et T1133 sont les plus courantes après "Unknown", ce qui suggère que ces méthodes sont des vecteurs d'attaque privilégiés.

Certaines attaques combinent plusieurs techniques , ce qui signifie qu'un modèle de détection efficace doit prendre en compte les relations entre ces différentes méthodes .

```{r incident-Grade-visualisation}
IncidentGrade_count <- df %>%
  group_by(IncidentGrade) %>%
  summarise(Count = n()) 

ggplot(data = IncidentGrade_count, 
       aes(x = fct_reorder(IncidentGrade, Count), y = Count)) +  
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "Distribution des Incident Grades",
    x = "Incident",
    y = " "
  ) +
  theme_minimal()

```

**Interpretation** :  Le nombre élevé de BenignPositive et FalsePositive indique que le système génère beaucoup d'alertes inutiles (bruit).Ce qui est contre productif.
Une première recommandation est déjà de  rafinner et  d'améliorer le système d'alerte pour qu'il capte moin de bruit.


```{r repartition-categories}
category_counts <- df %>%
  count(Category, name = "Count") %>%  
  arrange(desc(Count))  

top_4_categories <- category_counts %>%
  head(4) 


autres_count <- sum(category_counts$Count) - sum(top_4_categories$Count)

top_5_categories <- top_4_categories %>%
  add_row(Category = "Autres", Count = autres_count)


ggplot(top_5_categories, aes(x = fct_reorder(Category, Count), y = Count, fill = Category)) +
  geom_bar(stat = "identity") +
  coord_flip() +  # Met les barres à l'horizontale
  labs(title = "Distribution des Catégories", x = "Catégorie", y = "Nombre") +
  theme_minimal() +
  scale_fill_viridis_d()


```


**interpretation** :

*Initial Access*est la catégorie la plus fréquente Cela signifie que la majorité des alertes concernent des tentatives d'accès initiales (ex. hameçonnage, exploitation de vulnérabilités).

*Exfiltration*arrive en deuxième position Cela correspond aux tentatives de vol de données en dehors du réseau cible ce qui indique aussi que des attaquants ont réussi à pénétrer les systèmes et tenter d'exfiltrer des informations sensibles.

*SuspiciousActivity* Comportements suspects qui ne sont pas nécessairement confirmés comme des attaques.
*CommandAndControl* Signale qu'un attaquant tente d'établir une communication avec un serveur distant.
*Impact* est la catégorie la moins fréquente cela signifie que les incidents ayant un effet direct et destructeur sont moins courants du à une bonne capacité de détection précoce.

*Autres* cette catégorie regroupe toutes les autres catégories moins fréquentes.

```{r IncidentGrade-fill-selon-IncidentGrade}
incident_counts <- df %>%
  count(IncidentGrade, name = "Count")

ggplot(incident_counts, aes(x = fct_reorder(IncidentGrade, Count), y = Count, fill = IncidentGrade)) +
  geom_bar(stat = "identity") +
  #coord_flip() +  # Met les barres à l'horizontale
  labs(title = "Distribution des Catégories", x = "Catégorie", y = "Nombre") +
  theme_minimal() +
  scale_fill_viridis_d()

```

**interpretation** 

*BenignPositive*(Majoritaire) représente une grande partie du graphique. Ce qui signifie que le système présent
capture énormément de fausses alertes. 

*TruePositive* (Proportion élevée) indique que le système de détection a bien identifié de véritables incidents qui sont des alertes valides et confirmées comme étant des menaces .
Une proportion élevée de TruePositiveest un bon signe car cela signifie que la détection est efficace.

*FalsePositive* (Moins fréquents) ce sont des alertes générées à tort. Une proportion trop élevée de FalsePositive peut poser problème , car cela signifie que l'algorithme génère trop d'alertes inutiles , ce qui peut surcharger les analystes et réduire la confiance dans le système.

**Puisque nous voulons faire une regression logistique pour prédire la variable 'IncidentGrade', nous allons
modifier cette dernière pour obtenir juste deux classes de la façon suivante :**

BenignPositive --> negatif

FalsePositive --> negatif

TruePositive --> positif

```{r modification-IncidentGrade, include=FALSE}
library(dplyr)

df <- df %>%
  mutate(
    IncidentGrade = case_when(
      IncidentGrade == "BenignPositive" ~ "negatif",
      IncidentGrade == "FalsePositive" ~ "negatif",
      IncidentGrade == "TruePositive" ~ "positif"
    )
  )

```


```{r IncidentGrade-fill-selon-EntityType}
ggplot(df, aes(x = EntityType, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = "Nombre d'incidents par type d'entité selon  IncidentGrade",
    x = " ",
    y = " "
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred" ))  + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

```

**interpretation**

Les entités les plus affectées sont Ip, Machine, User, etMailMessage,ces entités sont les plus exposées aux incidents de sécurité et nécessairement une surveillance renforcée.

*IncidentGrade* est positif(rouge) ce qui confirme Incidents, User, Ip, et Machine présente un nombre élevé d'incidents positifs ce qui signifie que ces entités sont fréquemment compromises ou impliquées dans des attaques avérées.

*IncidentGrade* est négatif(bleu) certaines entités ont un grand nombre d'incidents classés comme négatifs ( negatif en bleu) comme Ip, MailMessage, et Machine ce qui peut indiquer quil ya trop de fausses alertes,des règles de détection trop sensibles oubien un filtrage inadéquat des menaces réelles .

Certaines entités ont beaucoup d'incidents négatifs mais peu de positifs ( OAuthApplication, Process, CloudApplication) ce qui indique que ces entités sont moins susceptibles d'être réellement compromises ou que les règles de détection sont mal calibrées pour elles.

Ont peut donc
prioriser la protection des entités User, Ip, etMachine car ce sont les cibles les plus fréquentes des attaques.
Réduire les faux positifs sur certaines entités ( MailMessage, Ip) afin dajuster les règles de détection pour éviter les alertes inutiles.
Analyser plus en détail les entités OAuthApplication, Process, et CloudApplication et vérifier si elles sont vraiment vulnérables ou si elles génèrent trop de fausses alertes.

```{r IncidentGrade-fill-selon-SuspicionLevel}

ggplot(df, aes(x = SuspicionLevel, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = " IncidentGrade par niveau de suspicion",
    x = "Niveau de suspicion",
    y = "Nombre d'incidents"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred"))  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation**

La catégorie *Not Suspicious* représente l'écrasante majorité des incidents cela signifie que la plupart des alertes générées ne sont pas considérées comme suspectes. En gros le système de détection identifie beaucoup d'incidents mais les juge non suspects .

La catégorie *"Incriminated"* n'a pas de données visibles dans le graphique, ce qui suggère soit une absence de cas, soit un nombre très faible.

*IncidentGrade* est positif(rouge) : On observe une proportion importante d'incidents positifs dans *Not Suspicious* ce qui signifie que les menaces réelles sont classées comme «non suspectes»

*Suspicious* contient relativement peu d'incidents la plupart des incidents dans cette catégorie sont des incidents négatifs ( negatif) , ce qui signifie que le modèle considère rarement des événements comme véritablement suspects. Cela peut indiquer que les seuils de suspicion sont trop stricts et n'identifient pas assez d'attaques.

Il faut donc analyser les vrais incidents ( positif) dans *Not Suspicious* pour voir s'il ya des modèles d'attaques cachées.
Comparer avec d'autres variables ( MitreTechniques, EntityType) pour identifier les entités les plus touchées dans chaque catégorie.



```{r IncidentGrade-fill-selon-Usage}

ggplot(df, aes(x = Usage, fill = IncidentGrade)) +
  geom_bar() +
  labs(
    title = " IncidentGrade par Usage",
    x = "Usage",
    y = "Nombre d'incidents"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("negatif" ="skyblue" , "positif" ="indianred" ))  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation**

Les entités *Public* génèrent un nombre d'incidents nettement plus élevé que les entités Private.
Cela signifie que les ressources publiques (ex. serveurs accessibles sur Internet, services cloud publics) sont beaucoup plus ciblées par des activités suspectes ou malveillantes.

*IncidentGrade* est positif(rouge):Le nombre d'incidents *positifs* est plus élevé dans *Public* que dans *Private*.Cela signifie que les attaques réussies sont plus fréquentes sur des ressources publiques car elle sont plus exposés et vulnérables.

*IncidentGrade* est négatif(bleu) :Les entités *Public* génèrent également un nombre élevé d'incidents négatifs, ce qui signifie que beaucoup d'alertes sont non confirmées. Dans *Private*, la proportion d'incidents positifs et négatifs semble plus équilibrée.

Il faut donc analyser les incidents positifs en Public pour identifier les vecteurs d'attaque principaux et evaluer les écarts entre Public et Private afin de voir pourquoi les ressources privées ont-elles moins d'incidents confirmés.

```{r IncidentGrade-evolution-dans-le-temps}

incident_grade_monthly <- df %>%
  mutate(Month = floor_date(Timestamp, "month")) %>%
  group_by(Month, IncidentGrade) %>%
  summarise(Count = n(), .groups = 'drop')

# Graphique de l'évolution des IncidentGrade dans le temps

ggplot(incident_grade_monthly, aes(x = Month, y = Count, color = IncidentGrade)) +
  geom_line(size = 1) +
  labs(
    title = "Évolution de IncidentGrade dans le Temps",
    x = "Mois",
    y = "Nombre d'Incidents",
    color = "IncidentGrade"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("negatif" = "skyblue", "positif" = "red")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**interpretation** : On remarque que les déclarations d'incidents sont stables durant l'hivers.
et le système ne capture que les transactions frauduleuse.

C'est en mai et Juin que se dégagent la majorité des signalements. Possible lien avec 
tous les mouvements qui se déroulent durant l'été ? c'est une question qu'il faudra explorer.

Faisons un zoom sur les fluxtuations pendant le mois de mai


```{r incidents-mai}
start_date <- as.Date("2024-05-01")
end_date <- as.Date("2024-08-30")

filtered_data <- df %>%
  filter(Timestamp >= start_date & Timestamp <= end_date)

daily_counts <- filtered_data %>%
  group_by(Date = Timestamp) %>%
  summarise(Count = n(), .groups = "drop")

ggplot(daily_counts, aes(x = Date, y = Count)) +
  geom_line(color = "skyblue", size = 1) +
  geom_point(color = "skyblue") +
  labs(
    title = paste("Incidents reportés de ", format(start_date, "%B %Y"), "à", format(end_date, "%B %Y")),
    x = "Date",
    y = "Numbre d'ncidents"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_date(date_breaks = "7 days", date_labels = "%d-%b") +
  geom_hline(yintercept = mean(daily_counts$Count), linetype = "dashed", color = "red")


```

**Interprétation** : 

On observe une augmentation brutale autour du 1er juin , où le nombre d'incidents passe de moins de 500 à plus de 1500 en quelques jours du a des activité malveillante.Après le pic début juin, le nombre d'incidents commence à redescendre , avec une apparition notable entre le 6 et le 13 juin.Une tendance clairement baissière après le 13 juin ce qui es du surement a une réponse efficace des équipes de cybersécurité ou une résolution des problèmes détectés début juin.
La ligne rouge indique la moyenne du nombre d'incidents sur la période .

Analysons les incidents entre le 1er et le 6 juin afin d'dentifier la cause du pic, vérifiions l'impact des contre-mesures après le 13 juin  Ont-elles été efficaces ?

**Un approche serait de limiter notre étude aux incidents se produisant entre le 16 mai et le 13 juin,
pour capter le flux de variation et optimiser le  modèle. Mais nous n'allons pas le faire dans le cadre de ce travail.**


### Analyse par composantes principales.

Avant de commencer à batir des modèles sur notre set de données, On va d'abord réduire la dimensionnalité
pour travailler uniquement avec les variables qui expliquent mieux la variabilité des données. mais comme toutes les colonnes en dehors de Timestamp  sont catégorielles, on va les convertir en numériques.


Comptons le nombre de valeurs distinctes par colonnes pour déterminer le meilleur algorithme de conversion.



```{r valeurs-distinctes-par-colonne}
distinct_counts <- c()

for (col in colnames(df)) {
  distinct_counts[col] <- length(unique(df[[col]]))
}

df_resume <- data.frame(
  Colonne = names(distinct_counts),
  Nb_Valeurs_Distinctes = as.integer(distinct_counts)
)
df_resume
```

Il y a trop des colonnes ayant énormément de valeurs distinctes, ce problème rend impossible l'annalyse PCA, puisque nous n'avons pas assez de ressources pour le faire.

Pour contourner le problème, on va faire un oneHot Encoder uniquement sur les colonnes ayant 10 ou moins de 10 valeurs distinctes.

Quant aux autres colonnes, on va faire un encodage des fréquences. Nous sommes consciens que ca va un peu biaiser le résultat, mais c'est le seul moyen de se faire une idée sur les variables avec les ressources en notre disposition.

```{r compter-valeurs-distinctes-df}
df_10_et_moins <- df_resume[df_resume$Nb_Valeurs_Distinctes <= 10, ]
df_plus_10     <- df_resume[df_resume$Nb_Valeurs_Distinctes > 10, ]

df_10_et_moins <- df[, df_10_et_moins$Colonne]
df_plus_10 <- df[,df_plus_10$Colonne]
```


Le colonnes ont énnormément de valeurs distinctes, le meilleur algorithme ici sera **embeddings**, mais nous n'avons pas acces aux super calculateurs pour la mettre en oeuvre. 

Nous allons donc opter pour  **l'encodage à laide des proportions** sur les colonnes ayant plus de 10 valeurs distinctes, et l' Encodage One-Hot pour les autres colones.


```{r one-hot-encoder}
df_onehot <- dummy_cols(df_10_et_moins, remove_first_dummy = FALSE, remove_selected_columns = TRUE)

```
```{r encodage-frequences}
# Fonction pour encoder les fréquences
encode_frequencies <- function(df) {
  df_encoded <- df  # c'est pour eviter d'ecraser df
  
  for (col in colnames(df)) {
    if (is.factor(df[[col]]) | is.character(df[[col]])) {
      freq_table <- table(df[[col]])  # Créer la table des fréquences
      df_encoded[[col]] <- as.integer(factor(df[[col]], levels = names(freq_table)))  # Encoder les fréquences
    }
  }
  
  return(df_encoded)
}

# Appliquer la fonction à ton dataframe
df_encoded <- encode_frequencies(df_plus_10)

```


```{r reconstitue-df}

df_copie <- cbind(df_onehot, df_encoded)
df_copie <- df_copie[, sapply(df_copie, is.numeric)]
df_copie
```





```{r PCA}
#par(mfrow = c(1, 2))
pr.out <- prcomp(df_copie, scale = TRUE) 
names(pr.out) 
biplot(pr.out, scale = 0)

plot(pr.out)
```

```{r visualisation PCA}
par(mfrow = c(1, 2))
pve <- summary(pr.out)$importance[2, ]

plot(pve, xlab = "Composante Principale",
     ylab = "Proportion de variance expliquée", 
     ylim = c(0, 1), type = "b",
     main = "Variance expliquée")

plot(cumsum(pve), xlab = "Composante Principale",
     ylab = "Variance expliquée cumulative", 
     ylim = c(0, 1), type = "b",
     main = "Variance expliquée cumulée")

```


Avec 20 composantes principales, on es capable d'expliquer environ 90% de la variabilité des observations.

### Méthode des k-means

```{r diagramme-ebouli}
set.seed(2025)
for (k in 1:15) {
  km <- kmeans(df_copie, centers = k, nstart = 20)
  wss[k] <- km$tot.withinss
}


df_wss <- data.frame(
  k = 1:15,
  WSS = wss
)


ggplot(df_wss, aes(x = k, y = WSS)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:15) +
  labs(
    title = "Diagramme d’éboulis (k-means)",
    x = "Nombre de clusters",
    y = "Somme des carrés intra-cluster (WSS)"
  ) +
  theme_minimal()

```

On voit que le coude se trouveentre 2 et 4, donc il est égal à 3. Ainsi, il est judicieux de diviser le set en
3 clusters.

```{r regroupement-m-means}
km.out <- kmeans(df_copie, 3, nstart = 30)
km.out$size
```
On ne peut pas visualiser les cluster à cause de la dimensionnalité. Mais nous pouvons quand meme remarquer 
qu'il y a trois groupes différents ayant pour taimmes respectives 15520 observations, 5465 observations et 4015 observations.

Il est possibles que ces groupes correspondent aux transaction frauduleuses, non frauduleuses et pas encore classifiées (on ne peut pas encore se prononcer sur la cardinalité de chaque ensemble)

###  Regression logistique

```{r binarisation-variable-cible, include=FALSE}
df$IncidentGrade <- ifelse(df$IncidentGrade == "positif", 1, 0)

```




```{r regression-logistique,eval=FALSE}

glm.fits <- glm(IncidentGrade ~. , data = df , family = binomial)
summary(glm.fits)

```



**interpretation**: 

Les variables Timestamp, RegistryKey et Usage sont statistiquement significatives.

* Intercept (131.201) --> lorsqu'aucune des variables explicatives n'est prise en compte, IncidentGrade a une forte tendance à être considéré comme frauduleux .

* Timestamp = -0.006913 (p = 0.006) --> à mesure que le temps passe, les incident ont moins tendance à être catégorisés 
comme suspectes. Cet effet est statistiquement significatif.

* RegistryKey = 0.304977 (p = 0.027) --> certaines valeurs de RegistryKey augmentent les chances d’un incident frauduleux par rapport à une catégorie de référence. 

Une Piste est de regarder individuellement toutes les clés qui N'ont été utiliséee qu'une seule fois.

```{r registryKey}
Registry_counts <- df %>%
  count(RegistryKey, name = "Count") %>%
  arrange(desc(Count))
t(Registry_counts)%>%
  kable()
 
```


* Usage (-0.071423) : Cela pourrait signifier que plus une ressource (Usage) est utilisée, moins elle est associée à un incident de type frauduleux.  



```{r precidion-du-modele,eval=FALSE}
glm.fits <- glm(IncidentGrade ~ Timestamp + RegistryKey + Usage, 
                data = df_train, 
                family = binomial)
summary(glm.fits)
glm.props <- predict(glm.fits, df_train, type =  "response")
glm.pred <- ifelse(glm.props > 0.4, "Frauduleux", "Non Frauduleux")
IncidentGrade_train <- ifelse(df_train$IncidentGrade == 1, "Frauduleux", "Non Frauduleux")
table(glm.pred,IncidentGrade_train)
precision <- mean(glm.pred == IncidentGrade_train)
cat("La précision du modèle est : ", round(precision, 2))

```


La precision est  de 64 %  --> , Le modèle que nous venons de construire
est utile. nous allons maintenant le tester sur les données de test.


```{r tester-le-modele,eval=FALSE}

df_test$RegistryKey = as.integer(df_test$RegistryKey) 
df_test$Usage = as.integer(df_test$Usage) 

glm.props_test <- predict(glm.fits, df_test, type =  "response")
glm.pred_test <- ifelse(glm.props_test > 0.4, "Frauduleux", "Non Frauduleux")

IncidentGrade_test <- ifelse(df_test$IncidentGrade == 1, "Frauduleux", "Non Frauduleux")
table(glm.pred_test, IncidentGrade_test)
precision_test <- mean(glm.pred_test == IncidentGrade_test)
cat("\n Précision du modèle sur les données de test : ", round(precision_test, 2))

```

* Interpretation : le modèle a la même précision de 64% pour les données de test : 

C'est un bon modèle, il peut être déployé


## 4 Modèle Batit sur la vrai base de données au complet.

```{r deploiement-du-modele,eval=FALSE}
# On selectionne les colonnes utiles
 
df <- Database[, c("Timestamp", "RegistryKey", "Usage", "IncidentGrade")]
#On prepare les données sous la base de tout ce qui est dejà connu plus haut


df$Timestamp <- as.Date(df$Timestamp, format = "%Y-%m-%d")

df$RegistryKey = as.factor(df$RegistryKey)
df$IncidentGrade = as.factor(df$IncidentGrade) 
df$Usage = as.factor(df$Usage) 

df <- df %>%
  mutate(
    IncidentGrade = case_when(
      IncidentGrade == "BenignPositive" ~ "negatif",
      IncidentGrade == "FalsePositive" ~ "negatif",
      IncidentGrade == "TruePositive" ~ "positif"
    )
  )
df$IncidentGrade <- ifelse(df$IncidentGrade == "positif", 1, 0)



# La suite du code ne compile pas il nous faudrait un super calculateur.

#message d'erreur : Notre ordinateur n'a pas assez de memoire pour allouer 30.8 GO

# On effectue maintenant le test

#glm.fits <- glm(IncidentGrade ~ Timestamp + RegistryKey + Usage, 
          #      data = df, 
           #     family = binomial)
#summary(glm.fits)
#glm.props <- predict(glm.fits, df, type =  "response")
#glm.pred <- ifelse(glm.props > 0.4, "Frauduleux", "Non Frauduleux")
#IncidentGrade <- ifelse(df$IncidentGrade == 1, "Frauduleux", "Non Frauduleux")
#table(glm.pred,IncidentGrade)
#precision <- mean(glm.pred == IncidentGrade)
#cat("La précision du modèle est : ", round(precision, 2))

```


## Quelques recommandations  : 

1. Engager d'avantages des spécialistes en cibersécurité et former le personnel ;

2. Mettre sur pied des publicités de sensibilisation ; 

3. Mettre une surveillance accrue sur les ressources moins utilisées ;

4. Renforcer la surveillance et les mesures de sécurité en été ; 

5. Regarder particulièrement les opérations qui se sont effectuées avec les clés suivantes, dans l'ordre de priorité
descandante.

```{r operations-suspectes,eval=FALSE}
Registry_counts <- Database %>%
  count(RegistryKey, name = "Count") %>%
  filter(Count <= 2)%>%
  arrange(Count)

transactions_suspectes <- Database %>%
  filter(RegistryKey %in% Registry_counts$RegistryKey)

transactions_suspectes %>% 
  select(RegistryKey,AlertTitle, Category,LastVerdict,Usage)%>%
  head(25)%>%
  kable()
#La totalité sera fournies en fichier annexe nommé opérations suspectes
```
